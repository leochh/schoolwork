#+TOC: nil
* Algorithm Description
** Bisection method
   The bisection method in mathematics is a root-finding method that repeatedly
   bisects an interval and then selects a subinterval in which a subinterval
   in which a root must lie for further processing.
** Newton-Raphson method
   The Newton-Raphson method is a method for finding successively better
   approximations to the roots of a real-valued function. The formula of
   Newton-Raphson method: \[x_{n+1} = x_n - \frac{f(x_n)}{f'(x_n)}\]

* Proof
** Bisection method
   Assume the given number X_0 is positive. Because the symmetry of the positive
   and negative number on number axis, this algorithm should work for
   negative number if it works for positive number.

   I. If $x_0 > 1$, let $x_{high_0} = x_0$, $x_{low_0} = 0$, $x_{mid_0} = \frac{x_{high_0} + x_{low_0}}{2}$
   #+begin_src python :exports results :results file
   import matplotlib.pyplot as plt
   import numpy as np

   fig = plt.figure()
   ax = fig.add_subplot(111)

   a = [0,1,1.75,1.912931,2.625,3.5,7]
   plt.hlines(0,0,10)
   plt.ylim(-1,1)
   y = np.zeros(np.shape(a))
   plt.plot(a,y,'.',ms=6)
   ax.text(0,-0.1,r'0')
   ax.text(1,-0.1,r'1')
   ax.annotate(r'$x_{mid_1}$',xy=(1.75,0.01),xytext=(1.75,0.15),
               arrowprops=dict(arrowstyle="->"))
   ax.annotate(r'$\sqrt[3]{x_0}$',xy=(1.912931,-0.01),xytext=(1.912931,-0.2),
               arrowprops=dict(arrowstyle="->"))
   ax.annotate(r'$x_{mid_2}$',xy=(2.625,0.01),xytext=(2.625,0.15),
               arrowprops=dict(arrowstyle="->"))
   ax.text(3.5,-0.1,r'$x_{mid_0}$')
   ax.text(7,-0.1,r'$x_0$')
   plt.axis('off')
   plt.draw()
   plt.savefig('numberAxis1.png')
   return 'numberAxis1.png'
   #+end_src

   #+RESULTS:
   [[file:numberAxis1.png]]
       
       Step A: If $x^3_{mid_0} > x_0 \Rightarrow x_{mid_0} > \sqrt[3]{x}$,
               then let $x_{high_1} = x_{mid_0}$, $x_{low_1} = x_{low_0} = 0$, $x_{mid_1} = \frac{x_{high_1} + x_{low_1}}{2}$

       Step B: If $x^3_{mid_1} < x_0 \Rightarrow x_{mid_1} < \sqrt[3]{x}$,
               then let $x_{low_2} = x_{mid_1}$, $x_{high_2} = x_{high_1} = x_{mid_0}$, $x_{mid_2} = \frac{x_{high_2} + x_{low_2}}{2}$

       Repeat step A or B until $|x_{mid_{n+1}} - x_{mid_n}| < precision~error$

   II. If $x_0 < 1$, let $x_{high_0} = 1$, $x_{low_0} = x_0$, $x_{mid_0} = \frac{x_{high_0} + x_{low_0}}{2}$
   #+begin_src python :exports results :results file
   import matplotlib.pyplot as plt
   import numpy as np

   fig = plt.figure()
   ax = fig.add_subplot(111)
   a = [0,0.4,0.7,0.7368,0.775,0.85,1]
   plt.hlines(0,0,1.2)
   plt.ylim(-1,1)
   y = np.zeros(np.shape(a))
   plt.plot(a,y,'.',ms=6)
   ax.text(0,-0.1,r'0')
   ax.text(1,-0.1,r'1')
   ax.annotate(r'$x_{mid_1}$',xy=(0.85,0.01),xytext=(0.8,0.15),
               arrowprops=dict(arrowstyle="->"))
   ax.annotate(r'$\sqrt[3]{x_0}$',xy=(0.7368,-0.01),xytext=(0.73,-0.2),
               arrowprops=dict(arrowstyle="->"))
   ax.annotate(r'$x_{mid_2}$',xy=(0.775,0.01),xytext=(0.7,0.15),
               arrowprops=dict(arrowstyle="->"))
   ax.annotate(r'$x_{mid_0}$',xy=(0.7,0.01),xytext=(0.6,0.15),
               arrowprops=dict(arrowstyle="->"))
   ax.text(0.4,-0.1,r'$x_0$')
   plt.axis('off')

   plt.draw()
   plt.savefig('numberAxis2.png')
   return 'numberAxis2.png'
   #+end_src

   #+RESULTS:
   [[file:numberAxis2.png]]
       
       Step A: If $x^3_{mid_0} < x_0 \Rightarrow x_{mid_0} < \sqrt[3]{x}$,
               then let $x_{low_1} = x_{mid_0}$, $x_{high_1} = x_{high_0} = 1$, $x_{mid_1} = \frac{x_{high_1} + x_{low_1}}{2}$

       Step B: If $x^3_{mid_1} > x_0 \Rightarrow x_{mid_1} > \sqrt[3]{x}$,
               then let $x_{high_2} = x_{mid_1}$, $x_{low_2} = x_{low_1} = x_{mid_0}$, $x_{mid_2} = \frac{x_{high_2} + x_{low_2}}{2}$

       Repeat step A or B until $|x_{mid_{n+1}} - x_{mid_n}| < precision~error$
** Newton-Raphson method 
   #+begin_src python :exports results :results file
    import matplotlib.pyplot as plt
    import numpy as np

    fig = plt.figure()
    ax = fig.add_subplot(111)

    ax.spines['left'].set_position(('data',0))
    ax.spines['bottom'].set_position(('data',0))
    ax.spines['right'].set_color('none')
    ax.spines['top'].set_color('none')

    plt.xlim(-2,10)
    plt.ylim(-100,500)
    xcood = np.arange(-2, 10, 0.01)
    x0 = 7

    def f(x):
        return np.power(x,3) - x0

    def tan(xn):
        fprime = 3 * xn * xn
        return f(xn) + fprime * (xcood - xn)

    xarray = np.array([x0])
    for t in range(2):
        a = xarray[t]
        ya = f(a)
        xarray = np.append(xarray,[a - ya/(3*a*a)])

    m = 0
    for t in xarray:
        tanx = tan(t)
        ycood = np.arange(-10, f(t)+25, 0.1)
        plt.plot(xcood,tanx,'-.r')
        plt.plot(np.repeat(t,np.shape(ycood)),ycood,'--b')
        ax.text(t-0.1,-30,r'$x_{%s}$' % m)
        m += 1

    ax.text(np.cbrt(x0)-0.3,15,r'$x_r = \sqrt[3]{x_0}$')   
    y = f(xcood)
    plt.plot(xcood, y)

    plt.draw()
    plt.savefig('numberAxis3.png')
    return 'numberAxis3.png'
   #+end_src

   #+RESULTS:
   [[file:numberAxis3.png]]

   Let $x_r = \sqrt[3]{x_0}$, so $f(x_r) = 0 ----~Eq.1$

   Given $x_{n+1} = x_n - \frac{f(x_n)}{f'(x_n)} ----~Eq.2$
   
   By Taylor Series,
   $$f(x_r) = f(x_n) + f'(x_n)(x_r - x_n) + \frac{f''(x_n)}{2!}(x_r-x_n)^2 + \frac{f'''(x_n)}{3!}(x_r-x_n)^3+\cdots$$
   
   Here I use the previous 3 items as the dominant polynomials.

   Let $f(x_r) \approx f(x_n) + f'(x_n)(x_r - x_n) + \frac{f''(x_n)}{2!}(x_r-x_n)^2 ----~Eq.3$

   Substitute Eq.1 and Eq.2 into Eq.3,

   $\Rightarrow 0 = f'(x_n)(x_n - x_{n+1}) + f'(x_n)(x_r - x_n) + \frac{f''(x_n)}{2!}(x_r-x_n)^2$

   $\Rightarrow x_{n+1} - x_r = \frac{f''(x_n)}{2!}(x_r-x_n)^2$

   Let error $e_n = x_n -x_r$,

   $\Rightarrow e_{n+1} = \frac{f''(x_n)}{2f'(x_n)}e^2_n$

   The last equation tells that after each iteration, the error in new estimate
   is proportional to the square of the old estimate. That means the precision digits will double for each iteration.

* Complexity Analysis

** Bisection method
   Define the time complexity is dependent on the required precision digit N. For
   example, a number 1.12345 with precision digit N=3 means the previous 3 digits after
   decimal point .123 are accurate. 
   
   Considering the worst case to determine one digit, for example, the current
   states are $x_{low_0} = 1.0$, $x_{high_0} = 2.0$ and the first accurate digit is 1.1.
   
   By definition $x_{mid_0} = \frac{x_{high_0} + x_{low_0}}{2}$, we can find
   $x_{mid_0} = 1.5$. Applying the same algorithm we can get $x_{mid_1} = 1.25$,
   $x_{mid_2} = 1.125$, $x_{mid_3} = 1.0625$, $x_{mid_4} = 1.09375$, $x_{mid_5}
   = 1.109375$. This shows that for the worst case, to find the interval where
   the accurate digit lies the program need to iterate 6 times to find the
   accurate digit. If the precision digit is N, then it needs at least 6N times
   to find the interval which satisfied the requirment. This indicates the time
   complexity of bisection method is O(N).

** Newton-Raphson method
   
